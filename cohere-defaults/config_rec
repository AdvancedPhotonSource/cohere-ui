// This file contains all configurable parameters that are applied during reconstruction.
// There are general parameters that apply to the main thread of reconstruction and features parameters.
// Reconstruction will use the global definitions and may use any of the supported features:
// twin, amp_support, phase_support, pcdi, resolution, average.
// The iterations during which the feature is active is defined by a trigger. In addition each feature may have other
// configurable parameters.
// Trigger can be defined as a single iteration, or multiple iterations.
// examples:
// (3) trigger at iteration 3
// (20, 5) trigger starts at iteration 20, repeats every 5 iteration for the rest of run
// (20, 5, 40) trigger starts at iteration 20, repeats every 5 iteration until iteration 40

// GENERAL
//data_dir = "phasing_data"
                             // directory from which data is read

//save_dir = "results"
                             // directory where results of reconstruction are saved as npy files
                             // if samples > 1, result from each thread will be stored in subdirectory 1,2,3 etc.

init_guess = "random"
                             // defines what to apply as initial guess. Choices are: random, continue, and AI_guess.
                             // "random" will generate random guess, "continue" will start from previously saved
                             // results, and "AI_guess" will start AI reconstruction that will be an initial guess

// continue_dir = "cont"
                             // valid if init_guess is "continue"
                             // Directory from which results are read for reconstruction continuation

// AI_trained_model
                             // valid and mandatory if init_guess is "AI_guess"
                             // defines the file of hdf5 format that holds trained model

reconstructions = 1
                             // number of reconstructions to start with
                             // typically used when running genetic algorithm

processing = "auto"
                             // optional, the library used when running reconstruction. When the auto option is
                             // selected the program will use the best performing library that is available, in the
                             // following order: cupy, af, numpy. The cp option will utilize cupy,
                             // np will utilize numpy, and af will leave selection to arrayfire. The cuda, opencl,
                             // and cpu are arrayfire libraries. The "cuda" and "opencl" options will invoke the
                             // processing on GPUs, and the "cpu" option on cpu. Default is auto.

device = [0,1]
                             // IDs of the target devices for each thread (reconstruction).
                             // If not defined, it will default to -1 for the OS to select device

algorithm_sequence = "3* (20*ER + 180*HIO) + 20*ER"
                            // mandatory, defines algorithm applied in each iteration during modulus projection and
                            // during modulus. The "*" character means repeat, and the "+" means add to the sequence.
                            // The sequence may contain single brackets defining a group that will be repeated by the
                            // preceding multiplier. The alphabetic entries: 'ER', 'ERpc', 'HIO', 'HIOpc' define algorithms
                            // used in this iteration. The entries will invoke functions as follows:
                            // 'ER' definition will invoke 'er' and 'modulus' functions
                            // 'ERpc' will invoke 'er' and 'pc_modulus'
                            // 'HIO' will invoke 'hio' and 'modulus'
                            // 'HIOpc' will invoke 'hio' and 'pc_modulus'.
                            // The pc_modulus is implementation of modulus with partial coherence correction.
                            // If defining ERpc or HIOpc the pcdi feature must be activated. If not activated,
                            // the phasing will use modulus function instead.

hio_beta = .9
                             // used in hio algorithm

// GENERATIc ALGORITHM
// ga_generations = 4
                             // number of generations

// ga_metrics = ["chi", "sharpness"]
                             // defines which metric should be used to rank the reconstruction results
                             // supported:
                             // - 'chi' - the last error calculated as norm(rs_amplitudes - data)/norm(data)
                             //   The smallest 'chi' value is the best.
                             // - 'sharpness' - sum(power(abs(image), 4))
                             //   The smallest 'sharpness' value is the best.
                             // - 'summed_phase' -  angle(image) - sum(angle(image) * support) / sum(support)
                             //   where support is calculated with shrink wrap using hardcoded threshold=.2 and sigma=.5
                             //   The greatest 'summed_phase' value is the best.
                             // - 'area' - sum(support)
                             //   where support is calculated with shrink wrap using hardcoded threshold=.2 and sigma=.5
                             //   The greatest 'area' value is the best.

// ga_breed_modes = ["sqrt_ab", "2ab_a_b"]
                             // defines which breeding mode to use to populate new generation. If "none"
                             // there is no breeding.
                             // Breeding starts with choosing alpha image. The rest of the images are crossed with alpha.
                             // Before the crossing, the image, called beta is aligned with alpha, and phases in both of
                             // the arrays are normalized to derive ph_alpha = angle(alpha), and ph_beta = angle(beta)
                             // supported:
                             // 'sqrt_ab' - sqrt(abs(alpha) * abs(beta)) * exp(0.5j * (ph_beta + ph_alpha))
                             // 'pixel_switch' - where((cond > 0.5), beta, alpha), cond = random(shape(beta))
                             // 'b_pa' - abs(beta) * exp(1j * (ph_alpha))
                             // '2ab_a_b' - 2 * (beta * alpha) / (beta + alpha)
                             // '2a_b_pa' - (2 * abs(alpha) - abs(beta)) * exp(1j * ph_alpha)
                             // 'sqrt_ab_pa' - sqrt(abs(alpha) * abs(beta)) * exp(1j * ph_alpha)
                             // 'sqrt_ab_recip' - fftshift(ifft(fftshift(temp))), where temp is calculated below
                             //                      t1 = fftshift(fft(fftshift(beta)))
                             //                      t2 = fftshift(fft(fftshift(alpha)))
                             //                      temp = sqrt(abs(t1)*abs(t2))*exp(.5j*angle(t1))*exp(.5j*angle(t2))
                             // 'max_ab' - max(abs(alpha), abs(beta)) * exp(.5j * (ph_beta + ph_alpha))
                             // 'max_ab_pa' - max(abs(alpha), abs(beta)) * exp(1j * ph_alpha)
                             // 'avg_ab' - 0.5 * (alpha + beta)
                             // 'avg_ab_pa - 0.5 * (abs(alpha) + abs(beta)) * exp(1j * (ph_alpha))

// ga_cullings = [2,1]
                             // defines how many worst samples to remove in breeding phase for each generation
                             // defaults to 0

// ga_sw_thresholds = [.15, .1]
                             // the support is recalculated with this threshold after breeding phase
                             // defaults to support threshold

// ga_sw_gauss_sigmas = [1.1, 1.0]
                             // the support is recalculated with this sigma after breeding phase
                             // defaults to support sigma

// ga_lpf_sigmas = [2.0, 1.5]
                             // list of sigmas that will be used in subsequent generations to calculate
                             // Gauss (assuming algorithm is GAUSS) and apply it to the data
                             // This determines low resolution generations number

// ga_gen_pc_start = 3
                             // generation at which pcdi feature will start, if active.

// TWIN
// twin feature trims the image array at the current state by zeroing half of the array in each dimension.

twin_trigger = [2]
                             // twin defines at which iteration to cut half of the array(i.e. multiply by 0s),
                             // Comment out, if don't want to apply twin.
                             // when running GA applied only in first generation

twin_halves = [0, 0]
                             // defines which half of the array is zeroed out in x and y dimensions.
                             // If 0, the first half in that dimension is zeroed out, otherwise, the second half.

// SUPPORT
// Support area is an array that defines region in which the image is meaningful. This area is recalculated at the
// trigger iteration. The calculation employ an algorithm defined here as shrink_wrap_type.

sw_trigger = [1, 1]
                             // defines when to update support array using the parameters below.
                             // Comment out, if support feature not used.
sw_type = "GAUSS"
sw_threshold = 0.1
sw_gauss_sigma = 1.0
initial_support_area = [.5,.5,.5]
                             // initial support area. If the values are fractional, the support area will be calculated
                             // by multiplying by the data array dimensions. The support will be set to 1s to this
                             // dimensions centered.

// PHASE CONSTRAIN
// At the begginning iterations the support area is modified in respect to the phase. Support area will exclude points
// that phase is outside of the defined bounds

// phm_trigger = [0, 1, 310]
                             // defines when to update support array using the parameters below by applaying phase constrain.
                             // Comment out, if phase constrain feature not used.
                             // when running GA applied only in first generation
// phm_phase_min = -1.57
// phm_phase_max = 1.57

// PARTIAL COHERENCE
// Partial coherence triggers recalculation of coherence array for the amplitudes in reciprocal space.
// After first coherence array is determined, it is used for convolution in subsequent iteration.

// pc_interval = 50
                             // defines iteration interval to update coherence.
                             // Comment out, if pcdi feature not used.
// pc_type = "LUCY"
                             // partial coherence algorithm
// pc_LUCY_iterations = 20
// pc_normalize = True
// pc_LUCY_kernel = [16,16,16]
                             // coherence area. If the values are fractional, the coherence area will be calculated
                             // by multiplying by the data array dimensions.

// LOW RESOLUTION
// At the beginning iterations the data resolution and sigma used in recalculation of the support area are modified gradually.
// The sigma for each iteration where the low resolution is applied is a linespaced result of iter_res_sigma_range.
// The last sigma is typically set to shrink_wrap_gauss_sigma. If the last sigma is not specified, it defaults to shrink_wrap_gauss_sigma.
// The sigma is used by in recalculation of the support area, i.e when support trigger is on.
// The iter_res_det_range is similiary linespaced for the duration of low resolution iterations. The values are used
// as sigmas to calculate Gaussian distribution and applied (multiplied) to data.

// lpf_trigger = [0, 1, 320]
                             // defines when to apply low resolution using the parameters below.
                             // Comment out, if low resolution feature not used.
                             // when running GA applied only in first generation
// lpf_range = [.7, 1]
                             // used when applying low-pass data filter while iterating.
                             // The det values are linespaced for low resolution iterations from first value to last. 
                             // The filter is gauss with sigma of linespaced det. If only one number given,
                             // the last det will default to 1.
// lpf_sw_threshold = 0.1
                             // during lowpass iterations a GAUSS type shrink wrap is applied with
                             // this threshold ans sigma calculated as reverse of low pass filter

// AVERAGING
// The amplitudes of the last several iterations are averaged. This trigger defines at which iteration the averaging
// starts.

// average_trigger = [-65, 1]
                             // defines when to apply averaging. Negative start means it is offset from the last iteration
                             // Comment out, if averaging not used.

progress_trigger = [0, 5]
                             // defines when to print info on the console
                             // the info includes current iteration and error

